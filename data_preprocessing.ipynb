{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtraggio dei Dati Meteorologici\n",
    "\n",
    "Questo script Python carica un file CSV contenente dati meteorologici, filtra le righe in base a un intervallo di date specificato e salva i dati filtrati in un nuovo file CSV.\n",
    "\n",
    "### Dettagli del Codice:\n",
    "\n",
    "1. **Caricamento del CSV**: Il file CSV contenente i dati meteorologici viene caricato in un DataFrame.\n",
    "2. **Conversione della Data**: La colonna `ts_get` viene convertita in formato datetime per consentire il filtraggio.\n",
    "3. **Filtraggio**: Vengono selezionate solo le righe comprese tra il 1° agosto 2024 e il 1° ottobre 2024.\n",
    "4. **Salvataggio**: I dati filtrati vengono salvati in un nuovo file CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File salvato come: weather-010824-300924.csv\n"
     ]
    }
   ],
   "source": [
    "file_path = \"SmartCityQCWizard\\weather\\weather-010824-061024.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['ts_get'] = pd.to_datetime(df['ts_get'])\n",
    "\n",
    "start_date = '2024-08-01'\n",
    "end_date = '2024-10-1'\n",
    "filtered_df = df[(df['ts_get'] >= start_date) & (df['ts_get'] <= end_date)]\n",
    "\n",
    "output_file = \"weather-010824-300924.csv\"\n",
    "filtered_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"File salvato come: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unione di File CSV di Presenza\n",
    "\n",
    "Questo script Python carica più file CSV contenenti dati di presenza, li unisce in un unico DataFrame e salva il risultato in un nuovo file CSV.\n",
    "\n",
    "### Dettagli del Codice:\n",
    "\n",
    "1. **Definizione dei Percorsi**: Viene creato un elenco di percorsi ai file CSV di presenza.\n",
    "2. **Caricamento dei CSV**: Ogni file CSV viene caricato in un DataFrame utilizzando una lista di comprensione.\n",
    "3. **Unione dei DataFrame**: I DataFrame caricati vengono concatenati in un unico DataFrame.\n",
    "4. **Salvataggio**: Il DataFrame combinato viene salvato in un nuovo file CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File combinato salvato come: presenza_010824-300924.csv\n"
     ]
    }
   ],
   "source": [
    "file_list = [\"SmartCityQCWizard\\\\unique_attendance_15\\\\presenza_15_010824-140824.csv\", \n",
    "             \"SmartCityQCWizard\\\\unique_attendance_15\\\\presenza_15_010924-140924.csv\", \n",
    "             \"SmartCityQCWizard\\\\unique_attendance_15\\\\presenza_15_011024-081024.csv\", \n",
    "             \"SmartCityQCWizard\\\\unique_attendance_15\\\\presenza_15_150824-310824.csv\", \n",
    "             \"SmartCityQCWizard\\\\unique_attendance_15\\\\presenza_15_150924_300924.csv\"]\n",
    "\n",
    "df_list = [pd.read_csv(file) for file in file_list]\n",
    "combined_df = pd.concat(df_list)\n",
    "\n",
    "output_file = \"presenza_010824-300924.csv\"\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"File combinato salvato come: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elaborazione e Suddivisione dei Dati di Traffico e Meteo\n",
    "\n",
    "Questo script Python carica dati di traffico e meteorologici, espande i dati meteorologici per allinearsi meglio agli intervalli di tempo del traffico, e divide i dati in file CSV separati per ciascuna area di analisi.\n",
    "\n",
    "### Dettagli del Codice:\n",
    "\n",
    "1. **Caricamento dei Dati**: I file CSV contenenti i dati di traffico e meteo vengono caricati in DataFrame.\n",
    "2. **Filtraggio delle Aree**: I dati di traffico vengono suddivisi in base all'area di analisi, creando un DataFrame separato per ciascuna area di Cagliari.\n",
    "3. **Espansione dei Dati Meteorologici**: I dati meteorologici vengono espansi per includere timestamp a intervalli di 15 minuti attorno all'ora originale.\n",
    "4. **Rounding e Merge**: I timestamp del traffico e dei dati meteorologici vengono arrotondati al quarto d'ora più vicino e uniti in un unico DataFrame.\n",
    "5. **Pulizia dei Dati**: Le colonne duplicate e non necessarie vengono rimosse, e le colonne vengono riorganizzate.\n",
    "6. **Divisione e Salvataggio**: I dati vengono divisi in file CSV per ciascuna area, oltre a salvare un file completo contenente tutti i dati uniti.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"presenza_010824-300924.csv\")\n",
    "\n",
    "df0 =df[df['areaAnalisi'].str.contains('Intero Comune')]\n",
    "df1 =df[df['areaAnalisi'].str.contains('Cagliari - 001')]\n",
    "df2 =df[df['areaAnalisi'].str.contains('Cagliari - 002')]\n",
    "df3 =df[df['areaAnalisi'].str.contains('Cagliari - 003')]\n",
    "df4 =df[df['areaAnalisi'].str.contains('Cagliari - 004')]\n",
    "df5 =df[df['areaAnalisi'].str.contains('Cagliari - 005')]\n",
    "df6 =df[df['areaAnalisi'].str.contains('Cagliari - 006')]\n",
    "df7 =df[df['areaAnalisi'].str.contains('Cagliari - 007')]\n",
    "df8 =df[df['areaAnalisi'].str.contains('Cagliari - 008')]\n",
    "df9 =df[df['areaAnalisi'].str.contains('Cagliari - 009')]\n",
    "df10 =df[df['areaAnalisi'].str.contains('Cagliari - 010')]\n",
    "df11 =df[df['areaAnalisi'].str.contains('Cagliari - 011')]\n",
    "df12 =df[df['areaAnalisi'].str.contains('Cagliari - 012')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File salvato: dataset_output\\df1.csv\n",
      "File salvato: dataset_output\\df2.csv\n",
      "File salvato: dataset_output\\df3.csv\n",
      "File salvato: dataset_output\\df4.csv\n",
      "File salvato: dataset_output\\df5.csv\n",
      "File salvato: dataset_output\\df6.csv\n",
      "File salvato: dataset_output\\df7.csv\n",
      "File salvato: dataset_output\\df8.csv\n",
      "File salvato: dataset_output\\df9.csv\n",
      "File salvato: dataset_output\\df10.csv\n",
      "File salvato: dataset_output\\df11.csv\n",
      "File salvato: dataset_output\\df12.csv\n",
      "File completo salvato: dataset_output\\dataset_completo.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_dir = 'dataset_output'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "df_traffico = pd.read_csv(r\"presenza_010824-300924.csv\")\n",
    "df_meteo = pd.read_csv(r\"weather-010824-300924.csv\")\n",
    "\n",
    "df_traffico['datetime'] = pd.to_datetime(df_traffico['datetime'])\n",
    "df_meteo['ts_get'] = pd.to_datetime(df_meteo['ts_get'])\n",
    "\n",
    "# Funzione per espandere i dati meteo mantenendo ts_get originale\n",
    "def expand_weather_data(df_meteo):\n",
    "    expanded_data = []\n",
    "    \n",
    "    for _, row in df_meteo.iterrows():\n",
    "        base_time = row['ts_get']\n",
    "        original_ts = row['ts_get']  # Manteniamo il timestamp originale\n",
    "        \n",
    "        # Genera timestamp per ±30 minuti intorno all'ora del dato meteo\n",
    "        for minutes in [-15, 0, 15, 30]:\n",
    "            new_time = base_time + timedelta(minutes=minutes)\n",
    "            new_row = row.copy()\n",
    "            new_row['matching_time'] = new_time  \n",
    "            new_row['ts_get'] = original_ts    \n",
    "            expanded_data.append(new_row)\n",
    "    \n",
    "    return pd.DataFrame(expanded_data)\n",
    "\n",
    "df_meteo_expanded = expand_weather_data(df_meteo)\n",
    "\n",
    "# Arrotonda i timestamp al quarto d'ora più vicino per il matching\n",
    "df_traffico['datetime_rounded'] = df_traffico['datetime'].dt.round('15min')\n",
    "df_meteo_expanded['datetime_rounded'] = df_meteo_expanded['matching_time'].dt.round('15min')\n",
    "\n",
    "# Esegui il merge dei dataset\n",
    "df_unito = pd.merge(df_traffico,\n",
    "                    df_meteo_expanded,\n",
    "                    left_on='datetime_rounded',\n",
    "                    right_on='datetime_rounded',\n",
    "                    how='left')\n",
    "\n",
    "# Pulizia delle colonne duplicate e non necessarie\n",
    "df_unito = df_unito.drop(['datetime_rounded', 'matching_time'], axis=1)\n",
    "\n",
    "# Riorganizza le colonne per avere le date all'inizio\n",
    "cols = df_unito.columns.tolist()\n",
    "cols = ['datetime', 'ts_get'] + [col for col in cols if col not in ['datetime', 'ts_get']]\n",
    "df_unito = df_unito[cols]\n",
    "\n",
    "# Dizionario delle regioni\n",
    "regioni = {\n",
    "    'Cagliari - 001': 'df1',\n",
    "    'Cagliari - 002': 'df2',\n",
    "    'Cagliari - 003': 'df3',\n",
    "    'Cagliari - 004': 'df4',\n",
    "    'Cagliari - 005': 'df5',\n",
    "    'Cagliari - 006': 'df6',\n",
    "    'Cagliari - 007': 'df7',\n",
    "    'Cagliari - 008': 'df8',\n",
    "    'Cagliari - 009': 'df9',\n",
    "    'Cagliari - 010': 'df10',\n",
    "    'Cagliari - 011': 'df11',\n",
    "    'Cagliari - 012': 'df12'\n",
    "}\n",
    "\n",
    "# Divisione e salvataggio dei dataframe per area\n",
    "for area, nome_df in regioni.items():\n",
    "    df_area = df_unito[df_unito['areaAnalisi'].str.contains(area)]\n",
    "    output_file = os.path.join(output_dir, f\"{nome_df}.csv\")\n",
    "    df_area.to_csv(output_file, index=False, date_format='%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"File salvato: {output_file}\")\n",
    "\n",
    "# Salva anche il dataset completo\n",
    "output_file_completo = os.path.join(output_dir, \"dataset_completo.csv\")\n",
    "df_unito.to_csv(output_file_completo, index=False, date_format='%Y-%m-%d %H:%M:%S')\n",
    "print(f\"File completo salvato: {output_file_completo}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
